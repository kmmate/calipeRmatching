% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/calipeRmatching.R
\name{cm_cm_estimated_propscore}
\alias{cm_cm_estimated_propscore}
\title{Caliper matching estimator for estimated propensity score.}
\usage{
cm_cm_estimated_propscore(
  y,
  d,
  x,
  modeltype,
  theta_hat,
  delta,
  estimate_variance = TRUE,
  beta = 1/4.000000001,
  alpha = 1/4.000000002,
  kappa_a = 10^(-15),
  kappa_gamma = 0.2,
  kappa_gamma_derivative = 0.5
)
}
\arguments{
\item{y}{\eqn{n}-long \code{numeric} \code{vector} \eqn{ (Y_1,Y_2,\ldots,Y_n) } of observations of the outcome variable.}

\item{d}{\eqn{n}-long \code{numeric} \code{vector} \eqn{ (D_1,D_2,\ldots,D_n) } of observations of the treatment indicator
variable. Each entry can be either 0 for control or 1 for treatment status.}

\item{x}{\eqn{n}-by-\eqn{k} \code{numeric} \code{array} of \eqn{n} observations of the \eqn{k} covariates \eqn{ (X_i)_{i\in[n]} \in R^{n\times k} }, \emph{not including} an intercept.}

\item{modeltype}{type of the generalised linear propensity score model \eqn{g}. Currently only "logit" (\eqn{g} is the logistic distribution function) or "probit" (\eqn{g} is the normal distribution function) are supported.}

\item{theta_hat}{estimated \eqn{(k+1)}-long coefficient vector \eqn{\hat\theta} of the propensity score model. 
The first entry corresponds to the intercept. It is assumed to be statistically independent of (\code{y},\code{d},\code{x}).}

\item{delta}{the caliper, a positive \code{numeric} variable. If zero is passed, then the default 
data-driven value is used (recommended). If a positive value is passed, that is used instead.}

\item{estimate_variance}{\code{logical} variable. If \code{TRUE}, the variances of the estimators are estimated.
If \code{FALSE}, no variance estimates are provided; this is useful to speed up execution.}

\item{beta}{a positive \code{numeric} variable, negative-exponent of bandwidth sequence \code{gamma_n} = \code{kappa_gamma} * \eqn{n} ^ (-\code{beta}) in nonparametric variance estimation. 
If zero  is passed, it is the default value (recommended), otherwise it is equal to the passed value.}

\item{alpha}{a positive \code{numeric} variable, negative-exponent of truncation sequence \code{a_n} = \code{kappa_a} * \eqn{n} ^ (-\code{alpha}) in nonparametric variance estimation. 
If zero  is passed, it is the default value (recommended), otherwise it is equal to the passed value.
Must be strictly smaller than \code{beta}.}

\item{kappa_a}{a positive \code{numeric} variable, scale of truncation sequence \code{a_n} = \code{kappa_a} * \eqn{n} ^ (-\code{alpha}) in nonparametric variance estimation. 
If zero  is passed, it is the default value, otherwise it is equal to the passed value.}

\item{kappa_gamma}{a positive \code{numeric} variable, scale of bandwidth sequence \code{gamma_n} = \code{kappa_gamma} * \eqn{n} ^ (-\code{beta}) in nonparametric variance estimation. 
If zero is passed, it is the default value, otherwise it is equal to the passed value.}

\item{kappa_gamma_derivative}{scale parameter of bandwidth sequence \code{gamma_derivative_n} = \code{kappa_gamma_derivative} * \eqn{n} ^ (-\code{beta}) in nonparametric variance estimation estimating derivatives w.r.t. \eqn{\theta}, the propensity score parameter. 
If zero is passed, a default value is used.}
}
\value{
A \code{List}, results from caliper matching estimation with elements:
\itemize{
\item \code{point_estimates}: a \code{List} with elements \itemize{ 
     \item \code{ate_hat}: estimated ATE; \eqn{\hat{\tau}_{\hat{\pi}}} in [KPV23].
     \item \code{att_hat}: estimated ATT; \eqn{\hat{\tau}_{t,\hat{\pi}}} in [KPV23].
     \item \code{var_hat_ate}: estimated asymptotic variance of \code{ate_hat}; \eqn{ \hat{V}_{\tau} + \hat{V}_{\sigma,\pi} } in [KPV23].
     \item \code{var_hat_att}: estimated asymptotic variance of \code{att_hat}; \eqn{ \hat{V}_{\tau_{t}} + \hat{V}_{t,\sigma,\pi} } in [KPV23].
     \item \code{var_hat_component_tau_ate}: the estimate \eqn{ \hat{V}_{\tau} } in [KPV23].
     \item \code{var_hat_component_tau_att}: the estimate \eqn{ \hat{V}_{\tau_{t}} } in [KPV23].
     \item \code{var_hat_component_sigmapi_ate}: the estimate \eqn{ \hat{V}_{\sigma,\pi} } in [KPV23].
     \item \code{var_hat_component_sigmapi_att}: the estimate \eqn{ \hat{V}_{t,\sigma,\pi} } in [KPV23].
     \item \code{var_hat_component_estpi_ate}: estimated variance component deriving from the estimation of the propensity score; the third term in Equation (14) in [KPV23].
     \item \code{var_hat_component_estpi_att}: estimated variance component deriving from the estimation of the propensity score; the third term in Equation (15) in [KPV23].
}
\item \code{delta}: caliper that is actually used. If zero was passed, then it is equal to the default data-driven value \eqn{\widehat{\overline{\underline{\Delta}}}_n \vee \frac{\log N_0}{N_0+1} \vee \frac{\log N_1}{N_1+1}} in the notation of Equation (13) in [KPV23].
                    If a positive value was passed, then it is equal to that instead.
\item \code{number_of_matches}: \eqn{n}-long \code{vector}, the number of matches for each unit.
\item \code{matched_pairs}: a 2-by-(number of matched pairs) \code{matrix}. A column with value \eqn{(i,j)} indicates that units \eqn{i} and \eqn{j} are matched. Indices start from 1, as opposed to from 0.
\item \code{var_estimation_settings}: a \code{List} with elements \itemize{
     \item \code{estimate_variance}: whether variance estimation is performed (\code{estimate_variance=TRUE}), or not (\code{estimate_variance=FALSE}).
     \item \code{a_n}: value of truncation sequence in nonparametric variance estimation. Equal to \code{kappa_a} * \eqn{n} ^ (-\code{alpha}).
     \item \code{gamma_n}:  value of bandwidth in nonparametric variance estimation. Equal to \code{kappa_gamma} * \eqn{n} ^ (-\code{beta}).
     \item \code{gamma_derivative_n}: value of bandwidth in nonparametric variance estimation used in derivative estimation w.r.t. propensity score parameter \eqn{\theta}. Equal to \code{kappa_gamma_derivative} * \eqn{n} ^ (-\code{beta}).
     \item \code{beta}: negative-exponent of bandwidth in nonparametric variance estimation that is actually used. If zero was passed, it is the default value, otherwise it is equal to the passed value.
     \item \code{alpha}: negative-exponent of truncation sequence in nonparametric variance estimation that is actually used. If zero was passed, it is the default value, otherwise it is equal to the passed value.
     \item \code{kappa_gamma}: scale of bandwidth sequence in nonparametric variance estimation that is actually used. If zero was passed, it is the default value, otherwise it is equal to the passed value.
     \item \code{kappa_a}: scale of truncation sequence in nonparametric variance estimation that is actually used. If zero was passed, it is the default value, otherwise it is equal to the passed value.
     \item \code{kappa_gamma_derivative}: negative-exponent of truncation sequence in nonparametric variance estimation that is actually used. If zero was passed, it is the default value, otherwise it is equal to the passed value.     
     \item \code{propscore_min}: the smallest propensity score value computed using \code{modeltype}, \code{x}, \code{theta_hat} as \eqn{ \min_{i\in[n]}g({\hat\theta}^{T} (1, X_i^T)^T) },
                                 where \eqn{X_i} is the covariate vector of the \eqn{i}th unit in \code{x}, \eqn{\hat\theta} is \code{theta_hat} and \eqn{g} is the distribution function of the logistic or the normal distribution as specified by the propensity score model type \code{modeltype}.
     \item \code{propscore_max}: the largest propensity score value computed using \code{modeltype}, \code{x}, \code{theta_hat} as \eqn{ \max_{i\in[n]}g({\hat\theta}^{T} (1, X_i^T)^T) }.
     \item \code{truncation_low}: lower truncation threshold for variance estimation = \code{propscore_min} + \code{a_n}.
     \item \code{truncation_high}: higher truncation threshold for variance estimation = \code{propscore_max} - \code{a_n}.
     }
}
}
\description{
Estimates the Average Treatment Effect (ATE) and 
Average Treatment Effect on the Treated (ATT) of a binary treatment \eqn{D} 
on an outcome \eqn{Y} using the caliper matching estimator and the estimated propensity score \eqn{ g({\hat\theta}^{T} (1, X^T)^T) }. 
It can also estimate the variances of these two matching estimators.
}
\section{Warning}{
 

It is advised to look at the variance components in the returned results. 
Undesirably, negative values may occur; this may indicate too strong truncation at the bounderies.
To resolve this, lower \code{kappa_a} to mitigate truncation. 
Alternatively, try adjusting \code{kappa_gamma} and/or \code{kappa_gamma_derivative}.
}

\section{Notes}{
 
\itemize{

\item The covariate matrix \code{x} must be numeric. Variables of type \code{factor} must be
transformed before being passed to \code{cm_cm_estimated_propscore}, which can be done by
\code{model.matrix} of \code{R}; see the Examples.


\item Asymptotically valid \eqn{100(1-a)\%} confidence intervals can be constructed for
\itemize{
  \item ATE as
     [\code{ate_hat - qnorm(1-a/2) * sqrt(var_hat_ate/n)},
      \code{ate_hat + qnorm(1-a/2) * sqrt(var_hat_ate/n)}];
   \item ATT as
     [\code{att_hat - qnorm(1-a/2) * sqrt(var_hat_att/n)},
      \code{att_hat + qnorm(1-a/2) * sqrt(var_hat_att/n)}],
  }
where \code{n = length(y)} for \code{y} that was passed as argument, \code{qnorm} is the standard normal quantile function in \code{R} and \eqn{a} is some user-specified value in the interval \eqn{(0,1)}.
\item For the validity of the confidence intervals, it is assumed that the propensity score parameter is estimated on a sample statistically
      independent of (\code{y},\code{d},\code{x}). See [KPV23] for details and the Examples for sample splitting.  
}
}

\examples{

###############################################################################
# Load package
###############################################################################
library("calipeRmatching")
cm_set_number_of_threads(1) # set number of parallel threads


###############################################################################
# Generate data
###############################################################################
# --- x
# generate n-by-k covariate matrix.
generate_x <- function(n, k){
  x <- array(0, dim=c(n, k))
  for (i in 1:n){
    for (j in 1:k){
      x[i, j] <- runif(1, min=-10, max=10) # Uniform[-10,10] covariates
    }
  }
  return(x)
}
# --- propensity score
# computes propensity score based on logistic model
compute_propscore <- function(x, theta, modeltype){#' 
  stopifnot(ncol(x)==2) # k=2 is assumed
  stopifnot(length(theta)== (2 + 1)) # k=2 is assumed
  stopifnot(modeltype == "logit") # logit model is assumed
  n <- nrow(x)
  k <- ncol(x)
 score <- vector(mode="numeric", n) # X*theta
  propscore <- vector(mode="numeric", n) # g(X*theta)
  for (i in 1:n){
    score_i = theta[1] # intercept
    for (j in 2:(k+1)){
      score_i <- score_i + theta[j] * x[i, j-1]
    }
    score[i] <- score_i
    propscore[i] <- plogis(score_i) # g(x_i^T*theta) propensity score
  }
  return(propscore)
}
# --- treatment
# generates treatment vector
generate_d <- function(propscore){
  n <- length(propscore)
  d <- vector(mode="numeric", n)
  for (i in 1:n){
    d[i] <- rbinom(1, 1, propscore[i]) # D_i | X_i ~ Bernoulli(g(X_i^T*theta))
  }
  return(d)
}
# --- outcome
# generates outcome y
generate_y <- function(x, d){
  n <- nrow(x)
  stopifnot(ncol(x)==2) # k=2 is assumed
  y <- vector(mode="numeric", n)
  mu0 <- 0.0
  mu1 <- 0.0 # imply ATE = mu1 - mu0 if E[X] = 0_k
  for (i in 1:n){
    y0i <- mu0 + 0.8 * x[i, 1] + 1.5 * x[i, 2] + 0.9 * rnorm(n=1)
    y1i <- mu1 + 3.1 * sin(x[i, 1]) - 1.8 * x[i, 2] + 1.1 * rnorm(n=1)
    y[i] <- y0i + d[i] * (y1i - y0i)
  }
  return(y) 
}
n <- 5000
k <- 2 # if changed, theta and the way that `y` is generated must  be changed too.
modeltype <- "logit" # if changed, the way that `propscore` is generated must be changed too.
theta <- c(0.004, 0.5, 0.2) # propensity score parameters; first entry is intercept
# generate data
x <- generate_x(n, k)
propscore <- compute_propscore(x, theta, modeltype)
d <- generate_d(propscore)
y <- generate_y(x, d)

###############################################################################
# Estimation (estimated propensity score)
###############################################################################

# settings
delta <- 0.0 # caliper; set to zero for default value
estimate_variance <- TRUE # do estimate variance
alpha <- 0.0
beta <- 0.0
kappa_a <- 0.0
kappa_gamma <- 0.0
kappa_gamma_derivative <- 0.0

# split sample
# (For real-wrold data use random partition of indices; here splitting at half is suitable)
ps_estimation_index <- 1:(n/2) # use first half of sample for propensity score estimation
cm_estimation_index <- ((n/2)+1):n # use second half of sample for matching estimation

# propensity score estimation
x_ps_df <- data.frame(x[ps_estimation_index,])
x_ps_model <- model.matrix(~ X1 + X2, x_ps_df) # covariate matrix with intercept
d_ps_model <- d[ps_estimation_index]
propscore_model_estimated <- glm.fit(x=x_ps_model, y=d_ps_model, family=binomial(link=modeltype))
theta_hat <- propscore_model_estimated$coefficients

# caliper matching
x_cm_df <- data.frame(x[cm_estimation_index,])
x_cm_model <- model.matrix(~ X1 + X2, x_cm_df)
x_cm_model <- x_cm_model[,-(1)] # caliper matching doesn't take intercept as input, so drop it
d_cm_model <- d[cm_estimation_index]
y_cm_model <- y[cm_estimation_index]

help("cm_cm_estimated_propscore")
result_estimated_propscore <- cm_cm_estimated_propscore(y_cm_model, d_cm_model, x_cm_model,
                                                        modeltype, theta_hat,
                                                        delta, estimate_variance,
                                                        beta, alpha, kappa_a, kappa_gamma,
                                                        kappa_gamma_derivative)
print(result_estimated_propscore)

ate_hat <- result_estimated_propscore$point_estimates$ate_hat
var_hat_ate <- result_estimated_propscore$point_estimates$var_hat_ate
# NOTE the use of y_cm_model not y:
ate_ci95_low <- ate_hat - qnorm(0.975) * sqrt(var_hat_ate/length(y_cm_model))
# NOTE the use of y_cm_model not y:
ate_ci95_high <- ate_hat + qnorm(0.975) * sqrt(var_hat_ate/length(y_cm_model))
print(sprintf("95\%\% asymptotically valid confidence interval for ATE: [\%f, \%f]",
              ate_ci95_low, ate_ci95_high)) 

}
\references{
[KPV23] Kormos, V. d. Pas, V. d. Vaart (2023): Asymptotics of Caliper Matching Estimators for Average Treatment Effects, https://arxiv.org/abs/2304.08373
}
\seealso{
\code{\link{cm_cm_known_propscore}}
}
\author{
Mate Kormos
}
